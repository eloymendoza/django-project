<!DOCTYPE html>
<html>
<head>
    <title>Detección de Rostros en Tiempo Real</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
<style>
    body {
        margin: 0;
        position: relative;
        height: 100vh;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    canvas, video {
        position: absolute;
        top: 0;
        left: 50%;
        transform: translateX(-50%);
        width: 100%; /* Establece el ancho al 50% de la ventana */
        height: auto; /* Mantiene la relación de aspecto */
    }
</style>

</head>
<body>
    <video id="video" width="720" height="560" autoplay muted></video>
    <canvas id="canvas"></canvas>
    <script>
        let canvas, displaySize;
        let isFrameSent = false; // Variable de control para evitar envíos múltiples
        const video = document.getElementById('video');
        const captureButton = document.getElementById('capture');

            Promise.all([
            faceapi.nets.faceExpressionNet.loadFromUri('/static/models') ,
                faceapi.nets.tinyFaceDetector.loadFromUri('/static/models'),
                faceapi.nets.faceLandmark68Net.loadFromUri('/static/models'),
                // Carga aquí otros modelos si los necesitas
            ]).then(startVideo);


            function startVideo() {
                navigator.getUserMedia(
                  { video: {} },
                  stream => {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                      video.play();
                      detectFaces(); // Iniciar detección de rostros después de que el video comienza a reproducirse
                    };
                  },
                  err => console.error(err)
                );
              }
              

        video.addEventListener('loadedmetadata', () => {
            // Crear canvas y añadirlo al DOM
            canvas = faceapi.createCanvasFromMedia(video);
            document.body.append(canvas);
            displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize);
            detectFaces(); // Ya no necesitas pasar canvas y displaySize
        });

        async function detectFaces() {
            const options = new faceapi.TinyFaceDetectorOptions();
            let detections = await faceapi.detectAllFaces(video, options)
              .withFaceLandmarks()
              .withFaceExpressions();
          
            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize);
          
            const resizedDetections = faceapi.resizeResults(detections, displaySize);
            canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
            faceapi.draw.drawDetections(canvas, resizedDetections);
            faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
            faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
          
            function calculateEyeOpenness(eyePoints) {
                const verticalDistance = faceapi.euclideanDistance([eyePoints[1].x, eyePoints[1].y], [eyePoints[5].x, eyePoints[5].y]);
                const horizontalDistance = faceapi.euclideanDistance([eyePoints[0].x, eyePoints[0].y], [eyePoints[3].x, eyePoints[3].y]);
                return verticalDistance / horizontalDistance; // Proporción de apertura del ojo
              }
              
            let lastBlinkTimestamp = 0;
            const blinkThreshold = 0.3; // Ajusta este valor
            const blinkCooldown = 1000; // Tiempo mínimo entre parpadeos, en milisegundos


            let eyeOpennessHistory = []; // Para almacenar la historia de la apertura de los ojos
            const historyLength = 10; // Cuántos frames para calcular el promedio móvil

            // Modifica la función calculateEyeOpenness para actualizar la historia de apertura de ojos
            function calculateEyeOpenness(eyePoints) {
                const verticalDistance = faceapi.euclideanDistance([eyePoints[1].x, eyePoints[1].y], [eyePoints[5].x, eyePoints[5].y]);
                const horizontalDistance = faceapi.euclideanDistance([eyePoints[0].x, eyePoints[0].y], [eyePoints[3].x, eyePoints[3].y]);
                const openness = verticalDistance / horizontalDistance;

                // Actualiza la historia de apertura de ojos
                eyeOpennessHistory.push(openness);
                if (eyeOpennessHistory.length > historyLength) {
                    eyeOpennessHistory.shift(); // Mantén el tamaño de la historia
                }

                return openness;
            }


            function drawCenterLines(canvas) {
                const ctx = canvas.getContext('2d');
                // Línea horizontal
                ctx.beginPath();
                ctx.moveTo(0, canvas.height / 2);
                ctx.lineTo(canvas.width, canvas.height / 2);
                ctx.strokeStyle = 'red';
                ctx.stroke();
            
                // Línea vertical
                ctx.beginPath();
                ctx.moveTo(canvas.width / 2, 0);
                ctx.lineTo(canvas.width / 2, canvas.height);
                ctx.strokeStyle = 'red';
                ctx.stroke();
            }

            function calculateCenterPoint(points) {
                return points.reduce((center, point) => {
                    return { x: center.x + point.x / points.length, y: center.y + point.y / points.length };
                }, { x: 0, y: 0 });
            }
            

            function getIdealReferencePosition(videoElement) {
    // Esto puede ser basado en la altura típica del usuario y la posición de la cámara
    const yOffset = videoElement.height * 0.3; // Ajustar según sea necesario
    return {
        x: videoElement.width / 2,
        y: videoElement.height / 2 + yOffset
    };
}

            
            resizedDetections.forEach(detection => {
              const now = Date.now();
              const landmarks = detection.landmarks.positions;
            
              // Índices de los puntos de referencia para los ojos izquierdo y derecho
              const leftEyeIndices = [36, 37, 38, 39, 40, 41];
              const rightEyeIndices = [42, 43, 44, 45, 46, 47];
            
              const leftEyePoints = leftEyeIndices.map(index => landmarks[index]);
              const rightEyePoints = rightEyeIndices.map(index => landmarks[index]);
            
              const leftEyeOpenness = calculateEyeOpenness(leftEyePoints);
              const rightEyeOpenness = calculateEyeOpenness(rightEyePoints);

            // Dibuja las líneas de centro fijas
            drawCenterLines(canvas);

            // Informar al usuario
            const ctx = canvas.getContext('2d');
            const faceCenter = calculateCenterPoint(detection.landmarks.positions);
            const canvasCenter = { x: canvas.width / 2, y: canvas.height / 2 };

            // Determina si el rostro está centrado (puedes ajustar el umbral de 'tolerance' según sea necesario)
            const tolerance = 10; // pixels
            const isCenteredHorizontally = Math.abs(faceCenter.x - canvasCenter.x) < tolerance;
            const isCenteredVertically = Math.abs(faceCenter.y - canvasCenter.y) < tolerance;              
            
            
              // Verifica si la detección de un parpadeo es válida
              if (leftEyeOpenness < blinkThreshold && rightEyeOpenness < blinkThreshold) {
                if (now - lastBlinkTimestamp > blinkCooldown) {
                  console.log("Blink detected!");
                  lastBlinkTimestamp = now;
                }
              }
            });
                         
            requestAnimationFrame(detectFaces);

        
        }
          
          // Asegúrate de llamar a detectFaces inicialmente o después de cargar el video
          detectFaces();
          

        function sendFrame() {

            if (isFrameSent) {
                return; // Evitar que la función se ejecute si ya se ha enviado el frame
            }

            isFrameSent = true; // Actualizar la variable de control

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            const data = canvas.toDataURL('image/jpeg');
            fetch('../api/ReconFacial/', {
                method: 'POST',
                body: JSON.stringify({ imagen_base64: data }),
                headers: {
                    'Content-Type': 'application/json',
                    'X-CSRFToken': getCookie('csrftoken')
                }
            })
                .then(response => response.json())
                .then(data => {
                    console.log(data);
                    if (data.match) {
                        // Si hay coincidencia, ocultamos el video y el canvas
                        video.style.display = 'none';
                        canvas.style.display = 'none';
                        // Detener la detección y el stream de la cámara
                        stopCameraStream();
                    } else {
                        alert("usuario no encontrado");
                        // Opcional: resetear isFrameSent si quieres permitir reintentos
                        isFrameSent = false;
                    }
                })
                .catch(error => {
                    console.error('Error al enviar la imagen:', error);
                    // Opcional: resetear isFrameSent si quieres permitir reintentos
                    isFrameSent = false;
                });

        }

        function stopCameraStream() {
            let stream = video.srcObject;
            if (stream) {
                let tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
            }
            video.srcObject = null;
        }


        // Función para obtener el CSRF token de Django
        function getCookie(name) {
            let cookieValue = null;
            if (document.cookie && document.cookie !== '') {
                const cookies = document.cookie.split(';');
                for (let i = 0; i < cookies.length; i++) {
                    const cookie = cookies[i].trim();
                    if (cookie.substring(0, name.length + 1) === (name + '=')) {
                        cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                        break;
                    }
                }
            }
            return cookieValue;
        }
    </script>
</body>
</html>